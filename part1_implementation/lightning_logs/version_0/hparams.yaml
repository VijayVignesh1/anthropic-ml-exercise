config:
  data:
    batch_size: 16
    num_workers: 2
    train_split: 0.8
    val_split: 0.2
  model:
    freeze_encoder: true
    learning_rate: 2e-4
    max_len: 256
    name: huawei-noah/TinyBERT_General_4L_312D
  paths:
    checkpoint_monitor: val_loss
    logger_dir: TinyBERT/logs
    models_dir: TinyBERT
  training:
    accelerator: auto
    devices: 1
    enable_progress_bar: true
    gradient_clip_val: 1.0
    log_every_n_steps: 10
    max_epochs: 20
    mode: min
    patience: 3
    save_last: true
    weight_decay: 1e-5
